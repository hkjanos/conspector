import requests
from bs4 import BeautifulSoup
import pyxploitdb


def check_exploit_for_cve(cve_id):
    """Check if an exploit exists for a given CVE ID."""
    if cve_id == "N/A":
        return "Could not check, no CVE available"

    print(f"Searching exploits for CVE ID: {cve_id}")
    try:
        # Step 1: Check ExploitDB
        exploits = pyxploitdb.searchCVE(cve_id)

        if exploits:
            exploit_link = exploits[0].link  # Assuming we use the first exploit found
            return f"Exploit available, see {exploit_link}"

        print(f"No direct exploits found in ExploitDB for CVE-{cve_id}. Switching to Brave search...")
    except Exception as e:
        print(f"Error querying ExploitDB: {e}")

    # Step 2: If not in ExploitDB, search using Brave
    search_results = brave_search(cve_id)
    if search_results:
        exploits = extract_exploit_info(search_results)
        exploit_found, likely_exploit_sources, found_urls = exploit_scan(exploits)

        if exploit_found:
            return f"Exploit likely available, see {', '.join(likely_exploit_sources)}"
        else:
            return "No mention of CVE in the largest exploitation databases (see documentation)"
    else:
        return "No search results found."


def brave_search(query):
    """Perform a search on Brave Search."""
    url = f"https://search.brave.com/search?q={query}"
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    response = requests.get(url, headers=headers)

    if response.status_code == 200:
        print("Request successful")
        soup = BeautifulSoup(response.text, 'html.parser')
        search_results = soup.find_all('a', {'class': 'svelte-yo6adg l1 heading-serpresult'})
        if search_results:
            print(f"Found {len(search_results)} results!")
            return search_results
        else:
            print("No search results found.")
            return []
    else:
        print(f"Request failed with status code {response.status_code}")
        return []


def extract_exploit_info(search_results):
    """Extract exploit info from search result elements."""
    exploits = []
    for result in search_results:
        title = result.find('div', class_='title')
        title_text = title.text.strip() if title else None
        link = result.get('href')
        site_name_tag = result.find('div', class_='sitename')
        site_name = site_name_tag.text.strip() if site_name_tag else None

        if title_text and link:
            exploits.append({
                'title': title_text,
                'link': link,
                'site_name': site_name
            })
    return exploits


def exploit_scan(search_results):
    """Scan the search results and determine if any trusted sources are found."""
    trusted_sites = [
        "exploit-db.com",
        "rapid7.com",
        "cxsecurity.com",
        "vulnerability-lab.com",
        "0day.today",
        "securityfocus.com",
        "packetstorm.news"
    ]
    found_urls = set()
    likely_exploit_sources = set()
    likely_exploit_found = False

    for result in search_results:
        link = result.get('link', '').lower()
        if link:
            found_urls.add(link)
        for trusted_site in trusted_sites:
            if trusted_site in link:
                likely_exploit_found = True
                likely_exploit_sources.add(link)

    return likely_exploit_found, likely_exploit_sources, found_urls


if __name__ == "__main__":
    # Example CVE ID to check
    cve_id_list = ["CVE-2018-1000656"]  # Replace with the desired CVE ID(s)
    for cve_id in cve_id_list:
        result = check_exploit_for_cve(cve_id)
        print(result)
